{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLURGrumyhuX56XdtENoZL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlan18/ML-AND-DS-ASSIGNMENT1/blob/main/C4_5_Algo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3zC8C1tuUrII"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class C45DecisionTreeClassifier:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "\n",
        "    # --------------------------\n",
        "    # 1. Calculate Entropy\n",
        "    # --------------------------\n",
        "    def entropy(self, y):\n",
        "        classes, counts = np.unique(y, return_counts=True)\n",
        "        probs = counts / counts.sum()\n",
        "        return -np.sum(probs * np.log2(probs + 1e-9))  # Add epsilon to avoid log(0)\n",
        "\n",
        "\n",
        "    # --------------------------\n",
        "    # 2. Calculate Gain Ratio\n",
        "    # --------------------------\n",
        "    def gain_ratio(self, X_column, y):\n",
        "        total_entropy = self.entropy(y)\n",
        "        values, counts = np.unique(X_column, return_counts=True)\n",
        "\n",
        "\n",
        "        weighted_entropy = 0\n",
        "        split_info = 0\n",
        "\n",
        "\n",
        "        for v, count in zip(values, counts):\n",
        "            y_subset = y[X_column == v]\n",
        "            weighted_entropy += (count / len(y)) * self.entropy(y_subset)\n",
        "            proportion = count / len(y)\n",
        "            split_info -= proportion * np.log2(proportion + 1e-9)\n",
        "\n",
        "\n",
        "        info_gain = total_entropy - weighted_entropy\n",
        "        gain_ratio = info_gain / (split_info + 1e-9)\n",
        "        return gain_ratio\n",
        "\n",
        "\n",
        "    # --------------------------\n",
        "    # 3. Select Best Attribute\n",
        "    # --------------------------\n",
        "    def best_attribute(self, X, y, features):\n",
        "        best_gain_ratio = -1\n",
        "        best_feature = None\n",
        "        for feature in features:\n",
        "            gain_ratio = self.gain_ratio(X[:, feature], y)\n",
        "            if gain_ratio > best_gain_ratio:\n",
        "                best_gain_ratio = gain_ratio\n",
        "                best_feature = feature\n",
        "        return best_feature\n",
        "\n",
        "\n",
        "    # --------------------------\n",
        "    # 4. Build the Decision Tree\n",
        "    # --------------------------\n",
        "    def build_tree(self, X, y, features, depth=0):\n",
        "        classes, counts = np.unique(y, return_counts=True)\n",
        "        majority_class = classes[np.argmax(counts)]\n",
        "\n",
        "\n",
        "        # Stopping conditions\n",
        "        if len(classes) == 1:\n",
        "            return classes[0]\n",
        "        if len(features) == 0 or (self.max_depth is not None and depth >= self.max_depth):\n",
        "            return majority_class\n",
        "\n",
        "\n",
        "        best_feat = self.best_attribute(X, y, features)\n",
        "        if best_feat is None:\n",
        "            return majority_class\n",
        "\n",
        "\n",
        "        tree = {best_feat: {}, \"_majority\": majority_class}\n",
        "        remaining_features = [f for f in features if f != best_feat]\n",
        "\n",
        "\n",
        "        for v in np.unique(X[:, best_feat]):\n",
        "            X_subset = X[X[:, best_feat] == v]\n",
        "            y_subset = y[X[:, best_feat] == v]\n",
        "            if len(y_subset) == 0:\n",
        "                tree[best_feat][v] = majority_class\n",
        "            else:\n",
        "                tree[best_feat][v] = self.build_tree(X_subset, y_subset, remaining_features, depth + 1)\n",
        "\n",
        "\n",
        "        return tree\n",
        "\n",
        "\n",
        "    # --------------------------\n",
        "    # 5. Fit the Model\n",
        "    # --------------------------\n",
        "    def fit(self, X, y):\n",
        "        features = list(range(X.shape[1]))\n",
        "        self.tree = self.build_tree(X, y, features)\n",
        "\n",
        "\n",
        "    # --------------------------\n",
        "    # 6. Predict\n",
        "    # --------------------------\n",
        "    def _predict_single(self, x, tree):\n",
        "        if not isinstance(tree, dict):\n",
        "            return tree\n",
        "        feature = [k for k in tree.keys() if k != \"_majority\"][0]\n",
        "        value = x[feature]\n",
        "        if value in tree[feature]:\n",
        "            return self._predict_single(x, tree[feature][value])\n",
        "        else:\n",
        "            return tree[\"_majority\"]\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_single(x, self.tree) for x in X])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Example Dataset: “Buy Computer” (Play Tennis Style)\n",
        "# --------------------------\n",
        "data = {\n",
        "    'Age': ['Youth', 'Youth', 'Middle', 'Senior', 'Senior', 'Senior', 'Middle', 'Youth', 'Youth', 'Senior', 'Youth', 'Middle', 'Middle', 'Senior'],\n",
        "    'Income': ['High', 'High', 'High', 'Medium', 'Low', 'Low', 'Low', 'Medium', 'Low', 'Medium', 'Medium', 'Medium', 'High', 'Medium'],\n",
        "    'Student': ['No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No'],\n",
        "    'Credit': ['Fair', 'Excellent', 'Fair', 'Fair', 'Fair', 'Excellent', 'Excellent', 'Fair', 'Fair', 'Fair', 'Excellent', 'Excellent', 'Fair', 'Excellent'],\n",
        "    'Buy': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "X = df.drop('Buy', axis=1).values\n",
        "y = df['Buy'].values\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Train C4.5 Classifier\n",
        "# --------------------------\n",
        "clf = C45DecisionTreeClassifier()\n",
        "clf.fit(X, y)\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Display Decision Tree\n",
        "# --------------------------\n",
        "print(\"\\nC4.5 Decision Tree:\\n\", clf.tree)\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Test Predictions\n",
        "# --------------------------\n",
        "y_pred = clf.predict(X)\n",
        "print(\"\\nPredictions:\", y_pred)\n",
        "print(\"Actual:\", y.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vrxwh7MoVDY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}